# ğŸ¥­ Mango - Supply Order Datathon 2025

SoluciÃ³n para el desafÃ­o de predicciÃ³n de demanda de Mango usando **XGBoost**.

## ğŸ“‹ DescripciÃ³n del DesafÃ­o

El objetivo es predecir la cantidad Ã³ptima de producciÃ³n para cada producto de la nueva temporada de Mango. Este es un problema complejo que involucra:

- ğŸ“Š PredicciÃ³n de ventas 9 meses en el futuro
- ğŸ†• Productos que aÃºn no existen
- â±ï¸ Series de tiempo cortas (16 semanas)
- ğŸ“ˆ IdentificaciÃ³n de tendencias emergentes

### MÃ©trica de EvaluaciÃ³n

El modelo se evalÃºa usando **VAR (Ventas Antes de Rebajas)**:

```
VAR = ventas a precio completo / producciÃ³n
```

La mÃ©trica personalizada penaliza mÃ¡s las **ventas perdidas** que el exceso de stock, reflejando el problema real del negocio.

## ğŸ¯ CaracterÃ­sticas del Proyecto

### âœ¨ Arquitectura del Modelo

- **Algoritmo principal**: XGBoost (Gradient Boosting)
- **OptimizaciÃ³n de hiperparÃ¡metros**: Optuna
- **ValidaciÃ³n**: K-Fold Cross-Validation (5 folds)
- **Feature Engineering**: MÃ¡s de 50+ features derivadas

### ğŸ”§ Features Implementadas

1. **Features Temporales**:
   - Mes, trimestre, semana del aÃ±o
   - Tipo de temporada (Primavera-Verano / OtoÃ±o-Invierno)
   - DuraciÃ³n del ciclo de vida

2. **Features Agregadas**:
   - EstadÃ­sticas por familia de producto
   - EstadÃ­sticas por categorÃ­a
   - EstadÃ­sticas por nÃºmero de tiendas
   - EstadÃ­sticas por temporada

3. **Features de InteracciÃ³n**:
   - Capacidad total (tiendas Ã— tamaÃ±os)
   - Potencial de ingresos (tiendas Ã— precio)
   - ExposiciÃ³n total (semanas Ã— tiendas)

4. **Features de Embeddings**:
   - EstadÃ­sticas de embeddings de imagen
   - Similitud entre productos

5. **Features de Lag**:
   - ProducciÃ³n de temporadas anteriores por familia
   - Tendencias temporales

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.8+
- pip o conda

### InstalaciÃ³n de Dependencias

```bash
# Clonar el repositorio
git clone https://github.com/gmorams/supply_order_datathon25.git
cd supply_order_datathon25

# Instalar dependencias
pip install -r requirements.txt
```

## ğŸ“ Estructura del Proyecto

```
supply_order_datathon25/
â”œâ”€â”€ data/                      # Datos (no incluidos en el repo)
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ sample_submission.csv
â”œâ”€â”€ models/                    # Modelos entrenados
â”œâ”€â”€ notebooks/                 # Notebooks de anÃ¡lisis
â”‚   â””â”€â”€ 01_exploratory_analysis.ipynb
â”œâ”€â”€ src/                       # CÃ³digo fuente
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â””â”€â”€ model.py
â”œâ”€â”€ submissions/               # Archivos de submission
â”œâ”€â”€ config.py                  # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ train.py                   # Script principal de entrenamiento
â”œâ”€â”€ requirements.txt           # Dependencias
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ’» Uso

### 1. Preparar los Datos

Coloca los archivos del datathon en la carpeta `data/`:
- `train.csv`
- `test.csv`
- `sample_submission.csv`

### 2. AnÃ¡lisis Exploratorio (Opcional)

```bash
jupyter notebook notebooks/01_exploratory_analysis.ipynb
```

### 3. Entrenar el Modelo

#### Entrenamiento BÃ¡sico

```bash
python train.py
```

#### Entrenamiento con OptimizaciÃ³n de HiperparÃ¡metros

```bash
python train.py --optimize
```

Este proceso:
1. âœ… Carga y preprocesa los datos
2. âœ… Crea features adicionales
3. âœ… Entrena el modelo con validaciÃ³n cruzada
4. âœ… Genera predicciones
5. âœ… Crea archivo de submission

### 4. Resultados

Los archivos generados se guardan en:
- **Modelo**: `models/xgboost_model.json`
- **Feature Importance**: `models/feature_importance.csv`
- **Submission**: `submissions/submission_YYYYMMDD_HHMMSS.csv`

## ğŸ“Š Resultados Esperados

El modelo estÃ¡ diseÃ±ado para:

- âœ… Maximizar el VAR (Ventas Antes de Rebajas)
- âœ… Minimizar ventas perdidas
- âœ… Reducir exceso de stock
- âœ… Adaptarse a diferentes familias de productos
- âœ… Capturar tendencias estacionales

### MÃ©tricas de EvaluaciÃ³n

Durante la validaciÃ³n cruzada, el modelo reporta:

| MÃ©trica | DescripciÃ³n |
|---------|-------------|
| **Custom Score** | Score personalizado (0-100) que penaliza ventas perdidas |
| **VAR** | Ventas a precio completo / producciÃ³n |
| **RMSE** | Root Mean Squared Error |
| **MAE** | Mean Absolute Error |
| **RÂ²** | Coeficiente de determinaciÃ³n |
| **Lost Sales** | Ventas perdidas promedio por producto |
| **Excess Stock** | Exceso de stock promedio por producto |

## ğŸ”¬ MetodologÃ­a

### 1. Feature Engineering

```python
from src.feature_engineering import FeatureEngineer

fe = FeatureEngineer()
train_processed = fe.fit_transform(train_df, categorical_features)
test_processed = fe.transform(test_df, categorical_features)
```

### 2. Entrenamiento del Modelo

```python
from src.model import DemandPredictor

predictor = DemandPredictor(params=xgboost_params)
cv_results = predictor.cross_validate(X_train, y_train, n_splits=5)
predictor.train(X_train, y_train)
```

### 3. GeneraciÃ³n de Predicciones

```python
predictions = predictor.predict(X_test)
submission = pd.DataFrame({
    'ID': test_ids,
    'Production': predictions
})
```

## ğŸ›ï¸ ConfiguraciÃ³n

Los parÃ¡metros del modelo se pueden ajustar en `config.py`:

```python
XGBOOST_PARAMS = {
    'objective': 'reg:squarederror',
    'max_depth': 8,
    'learning_rate': 0.05,
    'n_estimators': 1000,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    # ... mÃ¡s parÃ¡metros
}
```

## ğŸ”„ OptimizaciÃ³n de HiperparÃ¡metros

El proyecto incluye optimizaciÃ³n automÃ¡tica con Optuna:

```python
from src.model import optimize_hyperparameters

best_params = optimize_hyperparameters(
    X_train, y_train,
    n_trials=50,
    timeout=3600
)
```

## ğŸ“ˆ Mejoras Potenciales

### Corto Plazo
- [ ] Ensemble con LightGBM y CatBoost
- [ ] Feature selection automÃ¡tico
- [ ] CalibraciÃ³n de predicciones

### Medio Plazo
- [ ] Modelos especÃ­ficos por familia de producto
- [ ] Transfer learning con embeddings de imagen
- [ ] Features de similitud entre productos

### Largo Plazo
- [ ] Modelos de series de tiempo (LSTM, Transformer)
- [ ] Incorporar datos externos (tendencias, clima)
- [ ] Sistema de producciÃ³n con reentrenamiento automÃ¡tico

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Para contribuir:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Notas TÃ©cnicas

### Manejo de Valores Faltantes

- Features numÃ©ricas: ImputaciÃ³n con mediana
- Features categÃ³ricas: CategorÃ­a 'unknown'
- Embeddings: ImputaciÃ³n con 0

### Encoding de Variables CategÃ³ricas

- Target encoding para features con alta cardinalidad
- Frequency encoding como alternativa
- Label encoding para XGBoost (maneja categorÃ­as nativamente)

### ValidaciÃ³n

- K-Fold Cross-Validation estratificado
- Split temporal para validar predicciones futuras
- ValidaciÃ³n en subset de test durante el datathon

## ğŸ› SoluciÃ³n de Problemas

### Error: "train.csv not found"
AsegÃºrate de que los archivos de datos estÃ¡n en la carpeta `data/`.

### Error: Memory issues
Reduce el nÃºmero de features o usa submuestreo:
```python
train_df = train_df.sample(frac=0.8, random_state=42)
```

### Predicciones muy altas/bajas
Ajusta los parÃ¡metros del modelo en `config.py` o activa la optimizaciÃ³n:
```bash
python train.py --optimize
```

## ğŸ“š Referencias

- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [Scikit-learn Documentation](https://scikit-learn.org/)

## ğŸ‘¥ Autores

- **Tu Nombre** - *Desarrollador Principal*

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- Mango por organizar este desafÃ­o
- La comunidad de data science por las herramientas open-source
- Todos los participantes del datathon

---

**Â¡Buena suerte en el datathon! ğŸš€**

Si tienes preguntas o sugerencias, no dudes en abrir un issue en el repositorio.
